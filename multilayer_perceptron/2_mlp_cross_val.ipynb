{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Find the optimal hyperparameters for the multi layer perceptron model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#install libraries (if not already in environment)\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install pandas\n",
    "!pip install pyyaml h5py \n",
    "!pip install seaborn\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 982 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.1 scipy-1.5.4 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 831 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.5 pytz-2021.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
      "\u001b[K     |████████████████████████████████| 640 kB 617 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.19.5)\n",
      "Installing collected packages: pyyaml\n",
      "Successfully installed pyyaml-5.4.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 616 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adamax\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import auc, plot_roc_curve, roc_curve, mean_squared_error, accuracy_score, roc_auc_score, classification_report, confusion_matrix, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "#add path to the functions folder\n",
    "import sys\n",
    "sys.path.append('../onc_functions')\n",
    "\n",
    "# load custom function for building the NN\n",
    "from build_mlp import build_mlp \n",
    "\n",
    "# other libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print('tensorflow-' + tf.__version__)\n",
    "print('python-' + sys.version)\n",
    "print('sklearn-' + sklearn.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensorflow-2.4.1\n",
      "python-3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "[GCC 8.4.0]\n",
      "sklearn-0.24.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "with open('numeric_columns.pickle', 'rb') as f:  \n",
    "    nu_cols = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Model Layers\n",
    "\n",
    "- trying different weights (to handle the class imbalance) requires that you rerun the grid search with each weight"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "def mlp_cv(selected_class_weight, weight_name, imputation):\n",
    "    # fix random seed for reproducibility\n",
    "    seed = 78\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #import an imputed dataset\n",
    "    with open('complete' + str(imputation) + '.pickle', 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    #keep only the training data subsets\n",
    "    X_train =  dataset[dataset.subset <= 6].copy().sort_values(by = 'usrds_id')\n",
    "    del dataset\n",
    "\n",
    "    y_train = np.array(X_train.pop('died_in_90'))\n",
    "\n",
    "    #scale the numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    X_train[nu_cols] = scaler.fit_transform(X_train[nu_cols])\n",
    "    X_train = np.array(X_train.drop(columns=['subset','usrds_id','impnum'])) \n",
    "    print('scaled shape train ' + str(X_train.shape))\n",
    "\n",
    "\n",
    "    # Create a MirroredStrategy (can take advantage of a GPU if you have some, otherwise it just uses a single threaded approach)\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    # Open a strategy scope.\n",
    "    with strategy.scope():\n",
    "        # Everything that creates variables should be under the strategy scope.\n",
    "        # In general this is only model construction & `compile()`.\n",
    "        # Wrap Keras model so it can be used by scikit-learn\n",
    "\n",
    "        # grid search epochs, batch size and optimizer\n",
    "        neurons = [16,32, 64, 128]\n",
    "        layers = [1, 2]\n",
    "        kernel_regularizer = ['l2']\n",
    "        dropout_rate = [ 0.1, 0.2, 0.4, 0.5, 0.6]\n",
    "        learn_rate = [.001, .0001, .0002]\n",
    "        activation = ['relu', 'sigmoid', 'tanh']\n",
    "        optimizer = ['Adam']\n",
    "        epochs = [10, 20] # 1mill/256=4000 steps for one pass thru dataset\n",
    "        batches = [512, 256]\n",
    "        output_bias = [None]\n",
    "\n",
    "        params = dict(neurons=neurons, \n",
    "                          layers=layers,\n",
    "                          kernel_regularizer=kernel_regularizer, \n",
    "                          dropout_rate=dropout_rate,\n",
    "                          learn_rate=learn_rate, \n",
    "                          activation=activation,\n",
    "                          optimizer = optimizer,\n",
    "                          epochs=epochs, \n",
    "                          batch_size=batches, \n",
    "                          output_bias=output_bias)\n",
    "            \n",
    "        # early stopping for the epochs based on the auc under the precision recall curve\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                            monitor='auc_pr' ,\n",
    "                            verbose=1,\n",
    "                            patience=10,\n",
    "                            mode='max',\n",
    "                            restore_best_weights=True)\n",
    "        \n",
    "        # use the Keras wrapper for scikitlearn and our custom build_mlp function imported above\n",
    "        weighted_model_skl = KerasClassifier(build_fn=build_mlp, \n",
    "                                         verbose=0)\n",
    "\n",
    "        # evaluate using 5-fold cross validation\n",
    "        grid = GridSearchCV(\n",
    "                weighted_model_skl,\n",
    "                param_grid=params, \n",
    "                cv=2,\n",
    "                scoring='average_precision',\n",
    "                return_train_score=True,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "\n",
    "    print('fit model')\n",
    "    grid_result = grid.fit(\n",
    "                X_train, \n",
    "                y_train, \n",
    "                class_weight=selected_class_weight,\n",
    "                callbacks=[early_stopping]\n",
    "            )\n",
    "\n",
    "    # summarize results\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "                    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    \n",
    "    #save results\n",
    "    with open('./results/2021_grid_best_params_imp_' + str(imputation) + '_weight_' + str(weight_name) + '.pickle', 'wb') as f:  \n",
    "                    pickle.dump(grid_result.best_params_, f)\n",
    "\n",
    "    with open('./results/2021_grid_best_auc_imp_' + str(imputation) + '_weight_' + str(weight_name)  + '.pickle','wb') as f:  \n",
    "                    pickle.dump(grid_result.best_score_, f)\n",
    "\n",
    "    with open('./results/2021_grid_cv_results_imp_' + str(imputation) + '_weight_' + str(weight_name) + '.pickle','wb') as f:  \n",
    "                    pickle.dump(grid_result.cv_results_, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "total = 1150195\n",
    "positive_class_count =  86083      #(7.48% of total)\n",
    "neg_class_count = 1064112     #(92.52% of total)\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg_class_count)*(total)/2.0 \n",
    "weight_for_1 = (1 / positive_class_count)*(total)/2.0\n",
    "\n",
    "class_weight_m = {0: weight_for_0, 1: weight_for_1}\n",
    "class_weight_5 = {0: 1, 1: 5}\n",
    "class_weight_10 = {0: 1, 1: 10}\n",
    "class_weight_20 = {0: 1, 1: 20}\n",
    "\n",
    "#run the cross validation with the amount of weighting for each class \n",
    "mlp_cv(class_weight_20, weight_name=20, imputation=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "scaled shape train (804890, 294)\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n",
      "fit model n/\n",
      "Best: 0.235455 using {'activation': 'relu', 'batch_size': 256, 'dropout_rate': 0.2, 'epochs': 15, 'kernel_regularizer': 'l2', 'layers': 2, 'learn_rate': 0.0002, 'neurons': 32, 'optimizer': 'Adam', 'output_bias': None}\n",
      "0.234318 (0.009525) with: {'activation': 'relu', 'batch_size': 256, 'dropout_rate': 0.2, 'epochs': 10, 'kernel_regularizer': 'l2', 'layers': 2, 'learn_rate': 0.0002, 'neurons': 16, 'optimizer': 'Adam', 'output_bias': None}\n",
      "0.233863 (0.008253) with: {'activation': 'relu', 'batch_size': 256, 'dropout_rate': 0.2, 'epochs': 10, 'kernel_regularizer': 'l2', 'layers': 2, 'learn_rate': 0.0002, 'neurons': 32, 'optimizer': 'Adam', 'output_bias': None}\n",
      "0.235408 (0.007534) with: {'activation': 'relu', 'batch_size': 256, 'dropout_rate': 0.2, 'epochs': 15, 'kernel_regularizer': 'l2', 'layers': 2, 'learn_rate': 0.0002, 'neurons': 16, 'optimizer': 'Adam', 'output_bias': None}\n",
      "0.235455 (0.010428) with: {'activation': 'relu', 'batch_size': 256, 'dropout_rate': 0.2, 'epochs': 15, 'kernel_regularizer': 'l2', 'layers': 2, 'learn_rate': 0.0002, 'neurons': 32, 'optimizer': 'Adam', 'output_bias': None}\n",
      "params n/\n",
      "{'activation': 'relu', 'batch_size': 256, 'dropout_rate': 0.2, 'epochs': 15, 'kernel_regularizer': 'l2', 'layers': 2, 'learn_rate': 0.0002, 'neurons': 32, 'optimizer': 'Adam', 'output_bias': None}\n",
      "best score n/\n",
      "0.23545548460762972\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}